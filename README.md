# Back Propogation Network (Gradient Descent Method)

Project Status: Completed

Project Objective
The main objective of this project was to understand the working of Back Propogation Network (Gradient Descent Method) by manually coding each and every step in the process of Back Propogation Network and observing the change in weights as the model train itself to get the desired results

Method Used
Gradient descent method

Technology
R 

Project Description
In this project a Feed Forward network is built and the weights are updated using Back Propogation Network. It is a usual theoretical problem which is taught in neural network books to understand the working of Back Propogation Network, which is automated in this project using R to understand the ways the weights are updated, how do Sigmoidal Activation function is used to calculate the output, the effect of learning rate on the model's ability to achieve desired results. Anyone can find the question which is automated in any of the advanced Neural Network textbooks
